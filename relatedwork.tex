\section{Background and Related Work}
\begin{table*}
\small
\begin{center}
  \begin{tabular}{ c | c | c | c | c | c } 
      \multirow{2}{*}{\textbf{Systems}} & \multicolumn{2}{c|}{\textbf{Performance benefits}} &  \multicolumn{3}{c}{\textbf{Programming complexity}}   \\ \hhline{~-----}
       & Throughput & Latency & Program analysis & Concurrency bugs & Compensation logic \\ \hline
       COPS~\cite{lloyd2011don}/GentleRain~\cite{du2014gentlerain} &  Yes & Yes & N/A & Yes & Yes \\ \hline
       Gemini~\cite{li2012making} & Blue ops & Blue ops & Yes & No & No \\ \hline
       Consistency Rationing~\cite{kraska2009consistency} & Weak ops & Weak ops & Yes & Yes & Weak ops \\ \hline
       Salt Isolation~\cite{xie2014salt} & Base ops & Base ops & No & Base ops & N/A \\ \hline
       PLANET~\cite{pang2014planet}/ICG~\cite{icg} &  No  & Spec ops  & No & No & Spec ops \\ \hline
       STR &  Yes*  & Spec ops & No & No & Spec ops \\ \hline
  \end{tabular}
\end{center}
\caption{The tradeoffs between performance and programming complexity of existing systems}
\label{tab:related}
\end{table*}

\paragraph{Tradeoffs between performance and programming complexity} In the literature, various tradeoffs have been explored between programming complexity and system performance, which have intrigued different design of distributed datastores. These consistency models range from eventual consistency (causal consistency), which totally avoids synchronization among data replicas, to systems that mix strong and weak consistency levels. We start by listing different aspects of performance benefits as well as programming burdens that these models may bring, compared with a strongly-consistent model.

Two desirable performance improvement that can be brought by weakening consistency guarantees are \textbf{latency} and \textbf{throughput}. Low access latency is crucial for the user experience of online services, while higher throughput means a system is able to handle more concurrent requests. On the other hand, a weak consistency model may bring extra complexity for application developers. A most notable complexity is to cope with \textbf{concurrency anomalies}. In contrast to the ACID properties provided by conventional transactions, applications of a weakly-consistent datastore can observe effects of non-isolation, i.e. intersecting conflicting, transactions or partial updates of a transaction that requires ad-hoc logics to handle. Furthermore, some systems~\cite{helland2009building, icg, pang2014planet} choose to expose preliminary results of some operations to mask large operation latency, which requires programmers to write \textbf{compensation logic} for these operations in case they are incorrect and need to be emended. Last but not least, some systems mix multiple consistency levels, which requires a thorough \textbf{program analysis}, essentially to analyze possible interactions between all operations to ensure that executed some operations under weaker consistency will not compromise the correctness of applications.

\paragraph{Representative systems} In table \ref{tab:related}, we compare STR with several representative distributed datastores that relax consistency semantics to trade for better performance. Causally-consistent systems, like COPS~\cite{lloyd2011don} and GentleRain~\cite{du2014gentlerain}, propagate transactions asynchronously to remote datacenters (DCs). As no inter-DC synchronous is needed, these systems provide low operation latency and high throughput. However, this weak model can not prevent occurrence of concurrent conflicting transactions from different DCs, which causes concurrency anomalies and may need to be compensated.

Gemini~\cite{li2012making} requires programmers to analyze applications and identify (possibly with the aid of static analysis tools~\cite{atc-rodrigo}) which subset of application's operations commute and can safely take advantage of weak consistency semantics (blue operations). On the other hand, unlike STR, Gemini does not improve the performance of red operations (strongly-consistent operations).

Xie et. al.~\cite{xie2014salt} propose Salt Isolation, which allows classic ACID transactions to co-exist with BASE transactions, i.e., weakly consistent transactions that can externalize their intermediate state to minimize lock duration. Analogously to SPSI, Salt ensures that strong consistent transactions are not affected by the execution of weak consistent ones. Though, weakly consistency transactions (BASE) may observe the intermediate states of each other, which raises concurrent anomalies. On the contrary,  \specula ensures that \textit{any} transaction, even the ones that execute with weak consistency semantics, always observe and produce atomic and isolated snapshots (although potentially not reflecting the execution of concurrent transactions originated at different nodes).

Kraska et. al. allows programmers to specify which data shards demand strong consistency (serializability) and which ones can tolerate weak semantics (session guarantees), albeit possibly at some cost. This information is then exploited to dynamically adapt the consistency provided to transactions and reach an optimal balance between consistency and latency \cite{kraska2009consistency}. Unlike \specula, though, this approach only guarantee the weakest consistency semantics to transactions that access both weakly and strongly consistent data shards, which can not spare programmers from the need of handling concurrency bugs. Weak operations are speculative, therefore compensation logic is needed in case later on they have to be undone. \textbf{Make sure if program analysis is needed}.

PLANET~\cite{pang2014planet} and Incremental Consistency Guarantees (ICG)~\cite{icg} have explored the idea of exposing preliminary results, instead of final results that are produced after a global execution, to users to reduce perceived latency. The programming model exposed by PLANET and ICG aim to reduce the user-perceived latency by letting programmers expose the results of speculatively committed transactions. Unlike \specula, though, PLANET relies on a conventional/non-speculative data replication scheme that  never exposes pre-committed data to transactions. As such, PLANET can only benefit user-perceived latency, but fails to reduce the transaction's blocking time and, hence, to enhance throughput and reduce the time it takes to finalize the processing of a transaction. ICG does not support transactions, and delivering preliminary results brings considerable overhead. 

\iffalse
Recently, several datastores have been proposed that ensure strong consistency semantics in geo-replicated settings. Two notable examples are Spanner \cite{spanner} and Scatter \cite{scatter}, which provide Serializable transactions via the use of Two-phase commit and Paxos. In order to reduce commit latency in geo-replicated settings, some protocols have proposed variants of these techniques based on the assumption that data is fully replicated across different data-centers, i.e., each data-center maintains a full image of the system's data. To this end, Replicated Commit~\cite{mahmoud2013low} runs Two-Phase Commit multiple times in different datacenters and then uses Paxos to reach consensus as to whether the transaction should commit; MDCC~\cite{kraska2013mdcc} uses Generalized Paxos \cite{lamport2005generalized} to commit transaction, which takes only a single WAN round-trip in normal case. Unlike these works, \specula supports a more generic and scalable data-model, in which data can be partially replicated across a subset of the available data-centers.

An alternative approach that has been intensively explored in literature, and which also \specula supports, consists in supporting the simultaneous execution of transactions that use strong and weak consistency models. Gemini~\cite{li2012making} requires programmers to analyze applications and identify (possibly with the aid of static analysis tools~\cite{atc-rodrigo}) which subset of application's operations commute and can safely take advantage of weak consistency semantics.  Unlike \specula, Gemini, assumes a fully replicated data model and, as such, it does not address the issue of how to achieve isolation in presence of operations/transactions that require accessing  multiple data items scattered across different machines (see Figure~\ref{fig:example}).

Other recent approaches~\cite{zhang2013transaction,SwiftCloud,Walter} have aimed to reduce the cost of enforcing strong consistency, e.g., by identifying (possibly in a semi-automatic way) and exploiting the presence of commutative operations that can be executed without endangering consistency (as they are guaranteed to never conflict). Bumper~\cite{Diegues2013SRDS}  focuses on the problem of contention hot-spots, allowing to postpone the execution of conflict-prone operations issued within a transaction till their commit phase --- where they are executed after having acquired all the locks they require, and hence without risking to incur aborts. These approaches are orthogonal to \specula and  these mechanisms  could be combined with the speculative techniques  at the heart of \specula's replication protocol to further enhance its performance.

As discussed in \S \ref{sec:introduction}, this design choice spares programmers from the complexity of reasoning on subtle concurrency bugs that may lead applications running in non-sand-boxed environments  to exhibit arbitrary behaviours~\cite{opacity, virtualWorldConsistency}: this is the case, for instance, of applications that do not access data via well-defined query languages, like SQL, but rather by embedding transactions into arbitrary code written in a general purpose programming language, like Java~\cite{javaPersistenceAPI}. While, in the former case, inconsistencies lead to stale data being returned, but will not cause the data-store to crash, in the latter case, inconsistencies can lead applications to crash because of unexpected exceptions or to enter infinite loops~\cite{transactionsAreBackButTheyAreNotTheSame}. 

Unlike \specula, Gemini, assumes a fully replicated data model and, as such, it does not address the issue of how to achieve isolation in presence of operations/transactions that require accessing multiple data items scattered across different machines (see Figure~\ref{fig:example}).
\fi
 
\textbf{Other related work} Recently, several datastores have been proposed that ensure strong consistency semantics in geo-replicated settings. Two notable examples are Spanner \cite{spanner} and Scatter \cite{scatter}, which provide Serializable transactions via the use of Two-phase commit and Paxos. In order to reduce commit latency in geo-replicated settings, some protocols have proposed variants of these techniques based on the assumption that data is fully replicated across different data-centers, i.e., each data-center maintains a full image of the system's data. To this end, Replicated Commit~\cite{mahmoud2013low} runs Two-Phase Commit multiple times in different datacenters and then uses Paxos to reach consensus as to whether the transaction should commit; MDCC~\cite{kraska2013mdcc} uses Generalized Paxos \cite{lamport2005generalized} to commit transaction, which takes only a single WAN round-trip in normal case. Unlike these works, \specula supports a more generic and scalable data-model, in which data can be partially replicated across a subset of the available data-centers.

The idea of letting transactions ``optimistically'' borrow, in a controlled manner, the updated data of transactions currently in their commit phase has already been investigated in the past. Several works, e.g., SPECULA \cite{peluso2012specula} and Aggro \cite{palmieri2010aggro}, have applied this idea in contexts that are radically different from the ones considered in this paper, i.e., small scale clusters in which data is fully replicated via total-order based coordination primitives whereas \specula is designed for partially replicated data-stores distributed over geographical scale that ensure consistency via Two-phase commit.  SCC-kS~\cite{bestavros1996value}, PROMPT~\cite{PROMPT} and SL~\cite{Reddy} target a relatively closer system model, i.e., distributed databases, but do not support data replication and multi-version concurrency control, two mechanisms that are regarded as essential in modern, large scale online services~\cite{spanner,megastore,score}. Further, some of these proposals ~\cite{bestavros1996value, Romano-2014} rely on complex graph-based concurrency control techniques, whose efficiency has also been evaluated via simulation and that are likely to suffer from large overheads in realistic settings. Finally, unlike \specula PROMPT, SL and SCC-kS may expose non-atomic/isolated snapshots during transaction's execution.








